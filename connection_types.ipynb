{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Setting Connection Types and Options\n",
    "\n",
    "The sample code in this section demonstrates how to set connection types and connection options when connecting to extract, transform, and load (ETL) sources and sinks.\n",
    "\n",
    "**Note**\n",
    "When you create an ETL job that connects to Amazon DocumentDB, for the Connections job property, you must designate a connection object that specifies the virtual private cloud (VPC) in which Amazon DocumentDB is running. For the connection object, the connection type must be JDBC, and the JDBC URL must be mongo://<DocumentDB_host>:27017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "import time\n",
    "\n",
    "## @params: [JOB_NAME]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "output_path = \"s3://some_bucket/output/\" + str(time.time()) + \"/\"\n",
    "mongo_uri = \"mongodb://<mongo-instanced-ip-address>:27017\"\n",
    "mongo_ssl_uri = \"mongodb://<mongo-instanced-ip-address>:27017\"\n",
    "documentdb_uri = \"mongodb://<mongo-instanced-ip-address>:27017\"\n",
    "write_uri = \"mongodb://<mongo-instanced-ip-address>:27017\"\n",
    "documentdb_write_uri = \"mongodb://<mongo-instanced-ip-address>:27017\"\n",
    "\n",
    "read_docdb_options = {\n",
    "    \"uri\": documentdb_uri,\n",
    "    \"database\": \"test\",\n",
    "    \"collection\": \"coll\",\n",
    "    \"username\": \"username\",\n",
    "    \"password\": \"1234567890\",\n",
    "    \"ssl\": \"true\",\n",
    "    \"ssl.domain_match\": \"false\",\n",
    "    \"partitioner\": \"MongoSamplePartitioner\",\n",
    "    \"partitionerOptions.partitionSizeMB\": \"10\",\n",
    "    \"partitionerOptions.partitionKey\": \"_id\"\n",
    "}\n",
    "\n",
    "read_mongo_options = {\n",
    "    \"uri\": mongo_uri,\n",
    "    \"database\": \"test\",\n",
    "    \"collection\": \"coll\",\n",
    "    \"username\": \"username\",\n",
    "    \"password\": \"pwd\",\n",
    "    \"partitioner\": \"MongoSamplePartitioner\",\n",
    "    \"partitionerOptions.partitionSizeMB\": \"10\",\n",
    "    \"partitionerOptions.partitionKey\": \"_id\"}\n",
    "\n",
    "ssl_mongo_options = {\n",
    "    \"uri\": mongo_ssl_uri,\n",
    "    \"database\": \"test\",\n",
    "    \"collection\": \"coll\",\n",
    "    \"ssl\": \"true\",\n",
    "    \"ssl.domain_match\": \"false\"\n",
    "}\n",
    "\n",
    "write_mongo_options = {\n",
    "    \"uri\": write_uri,\n",
    "    \"database\": \"test\",\n",
    "    \"collection\": \"coll\",\n",
    "    \"username\": \"username\",\n",
    "    \"password\": \"pwd\"\n",
    "}\n",
    "write_documentdb_options = {\n",
    "    \"uri\": documentdb_write_uri,\n",
    "    \"database\": \"test\",\n",
    "    \"collection\": \"coll\",\n",
    "    \"username\": \"username\",\n",
    "    \"password\": \"pwd\"\n",
    "}\n",
    "\n",
    "# Get DynamicFrame from MongoDB and DocumentDB\n",
    "dynamic_frame = glueContext.create_dynamic_frame.from_options(connection_type=\"mongodb\",\n",
    "                                                              connection_options=read_mongo_options)\n",
    "dynamic_frame2 = glueContext.create_dynamic_frame.from_options(connection_type=\"documentdb\",\n",
    "                                                               connection_options=read_docdb_options)\n",
    "\n",
    "# Write DynamicFrame to MongoDB and DocumentDB\n",
    "glueContext.write_dynamic_frame.from_options(dynamic_frame, connection_type=\"mongodb\", connection_options=write_mongo_options)\n",
    "glueContext.write_dynamic_frame.from_options(dynamic_frame2, connection_type=\"documentdb\",\n",
    "                                             connection_options=write_documentdb_options)\n",
    "\n",
    "job.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Options for ETL Inputs and Outputs in AWS Glue\n",
    "**Note**\n",
    "Currently, the only formats that streaming ETL jobs support are JSON, CSV, Parquet, ORC, Avro, and Grok\n",
    "\n",
    "**Note**\n",
    "For writing Apache Parquet, AWS Glue ETL only supports writing to a governed table by specifying an option for a custom Parquet writer type optimized for Dynamic Frames. When writing to a governed table with the parquet format, you should add the key useGlueParquetWriter with a value of true in the table parameters.\n",
    "\n",
    "The following example shows how to specify the format options within an AWS Glue ETL job script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame = datasource1,\n",
    "    connection_type = \"s3\", \n",
    "    connection_options = {\n",
    "        \"path\": \"s3://s3path\"\n",
    "        }, \n",
    "    format = \"csv\", \n",
    "    format_options={\n",
    "        \"quoteChar\": -1, \n",
    "        \"separator\": \"|\"\n",
    "        }, \n",
    "    transformation_ctx = \"datasink2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the optimized reader with Arrow format, set \"optimizePerformance\" to true in the format_options or table property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glueContext.create_dynamic_frame.from_options(\n",
    "    frame = datasource1,\n",
    "    connection_type = \"s3\", \n",
    "    connection_options = {\"paths\": [\"s3://s3path\"]}, \n",
    "    format = \"csv\", \n",
    "    format_options={\n",
    "        \"optimizePerformance\": True, \n",
    "        \"separator\": \",\"\n",
    "        }, \n",
    "    transformation_ctx = \"datasink2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using vectorized SIMD JSON reader with Apache Arrow columnar format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from S3 data source        \n",
    "glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type = \"s3\", \n",
    "    connection_options = {\"paths\": [\"s3://s3path\"]}, \n",
    "    format = \"json\", \n",
    "    format_options={\n",
    "        \"optimizePerformance\": True,\n",
    "        \"withSchema\": SchemaString\n",
    "        })    \n",
    " \n",
    "# Read from catalog table\n",
    "glueContext.create_dynamic_frame.from_catalog(\n",
    "    database = database, \n",
    "    table_name = table, \n",
    "    additional_options = {\n",
    "    // The vectorized reader for JSON can read your schema from a catalog table property.\n",
    "        \"optimizePerformance\": True,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Schema Example\n",
    "This is an example of using the withSchema format option to specify the schema for XML data. We make use of the AWS Glue types, see PySpark Extension Types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsglue.gluetypes import *\n",
    "      \n",
    "schema = StructType([ \n",
    "  Field(\"id\", IntegerType()),\n",
    "  Field(\"name\", StringType()),\n",
    "  Field(\"nested\", StructType([\n",
    "    Field(\"x\", IntegerType()),\n",
    "    Field(\"y\", StringType()),\n",
    "    Field(\"z\", ChoiceType([IntegerType(), StringType()]))\n",
    "  ]))\n",
    "])\n",
    "\n",
    "datasource0 = create_dynamic_frame_from_options(\n",
    "    connection_type, \n",
    "    connection_options={\"paths\": [\"s3://xml_bucket/someprefix\"]},\n",
    "    format=\"xml\", \n",
    "    format_options={\"withSchema\": json.dumps(schema.jsonValue())},\n",
    "    transformation_ctx = \"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c69db75b480e4c127948eb459195a102407f15e89bb67469c7b13529e394f0d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
