{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference. Developing and testing AWS Glue job scripts - AWS Glue (amazon.com)\n",
    "\n",
    "\n",
    "\t1. Create an AWS named profile\n",
    "\t2. Open cmd on Windows and run the following command\n",
    "\tSET PROFILE_NAME=\"AWS_ATCG_PROFILE\"\n",
    "\t3. Run this command\n",
    "\tdocker pull amazon/aws-glue-libs:glue_libs_3.0.0_image_01\n",
    "\t4. Start container\n",
    "\n",
    "spark -submit\n",
    "You can run an AWS Glue job script by running the spark-submit command on the container\n",
    "\n",
    "\n",
    "\t1. Run this command to execute the spark -submit\n",
    "\n",
    "\t$ export PROFILE_NAME=\"AWS_ATCG_PROFILE\"\n",
    "\t$  export WORKSPACE_LOCATION=/home/glue_user/workspace/src\n",
    "\t$  export SCRIPT_FILE_NAME=sample.py \n",
    "\t$ mkdir -p {WORKSPACE_LOCATION}/src \n",
    "\t$ vim ${WORKSPACE_LOCATION}/src/${SCRIPT_FILE_NAME}\n",
    "\n",
    "\t$ docker run -it -v ~/.aws:/home/glue_user/.aws -v $WORKSPACE_LOCATION:/home/glue_user/workspace/src -e AWS_PROFILE=$PROFILE_NAME -e DISABLE_SSL=true --rm -p 4040:4040 -p 18080:18080 --name glue_spark_submit amazon/aws-glue-libs:glue_libs_3.0.0_image_01 spark-submit /home/glue_user/workspace/src/$SCRIPT_FILE_NAME\n",
    "\t\n",
    "REPL shell (Pyspark)\n",
    "\n",
    "You can run REPL (read-eval-print loops) shell for interactive development.\n",
    "Run the following command to execute the PySpark command on the container to start the REPL shell:\n",
    "\n",
    "docker run -it -v ~/.aws:/home/glue_user/.aws -e AWS_PROFILE=$PROFILE_NAME -e DISABLE_SSL=true --rm -p 4040:4040 -p 18080:18080 --name glue_pyspark amazon/aws-glue-libs:glue_libs_3.0.0_image_01 pyspark \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.py\n",
    "\n",
    "import sys\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.utils import getResolvedOptions\n",
    "\n",
    "\n",
    "class GluePythonSampleTest:\n",
    "    def __init__(self):\n",
    "        params = []\n",
    "        if '--JOB_NAME' in sys.argv:\n",
    "            params.append('JOB_NAME')\n",
    "        args = getResolvedOptions(sys.argv, params)\n",
    "\n",
    "        self.context = GlueContext(SparkContext.getOrCreate())\n",
    "        self.job = Job(self.context)\n",
    "\n",
    "        if 'JOB_NAME' in args:\n",
    "            jobname = args['JOB_NAME']\n",
    "        else:\n",
    "            jobname = \"test\"\n",
    "        self.job.init(jobname, args)\n",
    "\n",
    "    def run(self):\n",
    "        dyf = read_json(self.context, \"s3://awsglue-datasets/examples/us-legislators/all/persons.json\")\n",
    "        dyf.printSchema()\n",
    "\n",
    "        self.job.commit()\n",
    "\n",
    "\n",
    "def read_json(glue_context, path):\n",
    "    dynamicframe = glue_context.create_dynamic_frame.from_options(\n",
    "        connection_type='s3',\n",
    "        connection_options={\n",
    "            'paths': [path],\n",
    "            'recurse': True\n",
    "        },\n",
    "        format='json'\n",
    "    )\n",
    "    return dynamicframe\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    GluePythonSampleTest().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code requires Amazon S3 permissions in AWS IAM. You need to grant the IAM managed policy arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess or an IAM custom policy which allows you to call ListBucket and GetObject for the Amazon S3 path.\n",
    "\n",
    "test_sample.py: Sample code for unit test of sample.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sample.py\n",
    "\n",
    "import pytest\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.utils import getResolvedOptions\n",
    "import sys\n",
    "from src import sample\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"module\", autouse=True)\n",
    "def glue_context():\n",
    "    sys.argv.append('--JOB_NAME')\n",
    "    sys.argv.append('test_count')\n",
    "\n",
    "    args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "    context = GlueContext(SparkContext.getOrCreate())\n",
    "    job = Job(context)\n",
    "    job.init(args['JOB_NAME'], args)\n",
    "\n",
    "    yield(context)\n",
    "\n",
    "    job.commit()\n",
    "\n",
    "\n",
    "def test_counts(glue_context):\n",
    "    dyf = sample.read_json(glue_context, \"s3://awsglue-datasets/examples/us-legislators/all/persons.json\")\n",
    "    assert dyf.toDF().count() == 1961"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
